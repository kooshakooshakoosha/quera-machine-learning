{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d333515a",
   "metadata": {},
   "source": [
    "<h1 align=center style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "کامنت‌کاوی\n",
    "</font>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed20bff",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "مقدمه و صورت مسئله\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    در این تمرین کاربردی قصد داریم به حل یک مسئله‌ی دنیای واقعی بپردازیم که از جمله مسائل حوزه‌ی <i>پردازش زبان طبیعی (Natural Language Processing یا به اختصار NLP)</i> به شمار می‌رود. در متن‌ها اطلاعات و مفاهیم بسیاری نهفته است که کشف و سامان‌دهی آن‌ها می‌تواند منجر به تولید ارزش‌های زیادی در کاربردهای مختلف شود. یکی از رایج‌ترین سناریوها این است که یک شرکت، وبسایت یا اپلیکیشن قصد دارد کامنت‌های کاربران درباره‌ی محصول یا محصولات خود را به شکل‌های مختلف تحلیل کند تا براساس نتایج به‌دست‌آمده استراتژی کاری خود را تعیین کند. از آنجا که در شرکت‌های بزرگ تعداد کامنت‌های دریافتی بسیار زیاد است و عملاً نیروی انسانی قادر به بررسی تمام آن‌ها نیست از یادگیری ماشین جهت تحلیل و تفسیر این داده‌ها استفاده می‌شود. به عنوان مثال یکی از مسائل کاربردی در این حوزه به این شکل تعیین می‌شود که ماشین موظف است یک کامنت را مطالعه کرده و پیش‌بینی کند که بصورت کلی آیا این کامنت حسی مثبت دارد یا خیر. مثلاً در ارتباط با یک محصول، آیا کاربر از خرید و محصول دریافتی خود رضایت داشته است یا خیر.  به این کاربرد <i>تحلیل احساس (Sentiment Analysis)</i> گفته می‌شود. یا یک مسئله‌ی دیگر که با نام <i>عقیده‌کاوی (Opinion Mining)</i> شناخته می‌شود، کشف عقیده‌ی کاربر در ارتباط با جنبه‌های مختلف یک چیز مثلاً یک محصول است. به عنوان مثال عقیده‌ی کاربر درباره‌ی کیفیت ساخت، گارانتی، قیمت و موارد این چنینی چه بوده است. در این تمرین نیز ما قصد داریم مدلی طراحی کنیم که بتواند صرفاً پیش‌بینی کند آیا در یک کامنت، صحبتی درباره‌ی قیمت یک محصول شده است یا خیر. پس اجازه دهید شروع کنیم و کامنت‌ها را بکاویم تا به قیمت برسیم!\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5af1784",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "وارد کردن کتابخانه‌های مورد نیاز\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    ابتدا کتابخانه‌های مورد نیازتان را وارد کنید.\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99450f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from hazm import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "72faaed8",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "معرفی مجموعه‌داده\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "مجموعه‌داده‌ای که در اختیار شما قرار گرفته مربوط به کامنت‌های ثبت‌شده در وب‌سایت دیجی‌کالا است. هرکدام از کامنت‌های موجود در این مجموعه از نظر اینکه آیا صحبتی از قیمت محصول در آن شده یا خیر برچسب‌گذاری شده است.  ۴۰۰۰۰ کامنت برچسب‌گذاری‌شده به عنوان داده‌های آموزشی و ۸۰۰۰ کامنت دیگر نیز به عنوان داده‌های آزمون در دسترس شماست.\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "<center>\n",
    "<div dir=rtl style=\"direction: rtl;line-height:200%;font-family:vazir;font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    \n",
    "|ستون|توضیحات|\n",
    "|:------:|:---:|\n",
    "|<code>comment</code>|متن کامنت|\n",
    "|<code>price_value</code>|آیا درباره‌ی قیمت در آن صحبت شده (<code>1</code>) یا خیر (<code>0</code>)||\n",
    "    \n",
    "</font>\n",
    "</div>\n",
    "</center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e99bbe9b",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "خواندن مجموعه‌داده\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    در ابتدا نیاز است فایل‌های مجموعه‌داده را بخوانید. نمونه‌های آموزشی در فایل <code>train.csv</code> و نمونه‌های آزمون که باید برچسب آن‌ها را پیش‌بینی کنید در فایل <code>test.csv</code> ذخیره شده‌اند. اگر لازم دانستید می‌توانید به دلخواه خود بخشی از مجموعه‌ی آموزشی را به عنوان مجموعه‌ی اعتبارسنجی نیز جدا کنید.\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dcb9e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../data/train.csv') # To-Do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adb6ba5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('../data/test.csv') # To-Do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa49f610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>price_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>قیمت مناسب وکیفیت خوب پیشنهادمیکنم حتما خرید کنید</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>به اندازه یک میلیمتر دورتادور گوشی خالی میماند...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>از همه نظر عالی و یک خرید خوب در  قیمت حدود۴۰ ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>فقط یک بار هر یک ربع ساعت 1 درصد شارژ کرد بعدش...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>قیمت این کالا خیلی تغییر میکنه . من خریدم چندر...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>چیزی که تو عکس میبینید نیست\\r\\nسوکت ها از جنس ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>عالی بود هم راحت هم نرم و هم زیبا قیمت هم که ع...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>هنوز استفاده نکردم ولی خیلی ریز و نرم هستش خیل...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>چند هفته هست خریدم نسبت به تبلتهای موجود در با...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>برای مناطق سردسیر خیلی مناسب هستش چون دیگه هوا...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  price_value\n",
       "0  قیمت مناسب وکیفیت خوب پیشنهادمیکنم حتما خرید کنید            1\n",
       "1  به اندازه یک میلیمتر دورتادور گوشی خالی میماند...            0\n",
       "2  از همه نظر عالی و یک خرید خوب در  قیمت حدود۴۰ ...            1\n",
       "3  فقط یک بار هر یک ربع ساعت 1 درصد شارژ کرد بعدش...            0\n",
       "4  قیمت این کالا خیلی تغییر میکنه . من خریدم چندر...            1\n",
       "5  چیزی که تو عکس میبینید نیست\\r\\nسوکت ها از جنس ...            1\n",
       "6  عالی بود هم راحت هم نرم و هم زیبا قیمت هم که ع...            0\n",
       "7  هنوز استفاده نکردم ولی خیلی ریز و نرم هستش خیل...            0\n",
       "8  چند هفته هست خریدم نسبت به تبلتهای موجود در با...            0\n",
       "9  برای مناطق سردسیر خیلی مناسب هستش چون دیگه هوا...            0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f5ed163",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data = train_test_split(train_data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "edd8b41c",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "پیش‌پردازش و مهندسی ویژگی\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "پیش‌پردازش متن و نحوه‌ی بازنمایی آن به شکل عددی یکی از تاثیرگذارترین عوامل در عملکرد مدل است. در پیش‌پردازش باید سعی کنیم متن را به گونه‌ای پاک‌سازی کنیم که ویژگی‌های مفیدتری در آن دیده شود و کلمات نادر و بی‌اهمیت از آن حذف شوند تا کار مدل راحت‌تر شود. علاوه بر این از آنجا که ماشین تنها قادر به محاسبات عددی است و درکی از رشته‌ها ندارد باید بتوانیم از کلمات موجود در متن ویژگی‌های عددی بامعنایی تولید کنیم و آن‌ها را به عنوان ورودی مدل خود در نظر بگیریم.\n",
    "<br>\n",
    " تکنیک‌های پیش‌پردازش و پاک‌سازی متفاوتی برای متن وجود دارد که هم می‌توانید با جست‌وجو در اینترنت با آن‌ها آشنا شوید و هم می‌توانید از ایده‌های خلاقانه خودتان استفاده کنید. اما به چند نمونه از رایج‌ترین آن‌ها اشاره خواهیم کرد:\n",
    "</font>\n",
    "</p>\n",
    "<ul dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<li><b>حذف کلمات توقف (stop words):</b> برخی کلمات هستند که در متن‌ها به تعداد بسیار زیادی تکرار می‌شوند اما بار معنایی خاصی ندارند و معمولاً در مسائل مرتبط با پردازش زبان نه تنها تاثیر مثبتی در عملکرد مدل نمی‌گذارند بلکه پرتکرار بودن آن‌ها ارزش زیادی را به این کلمات می‌دهد. از جمله‌ی این کلمات در فارسی می‌توان به «از»، «به»، «است»، «آنان»، «آخر»، «آنجا» و ... اشاره کرد. شما می‌توانید در متن خود با توجه به مسئله‌ای که تعریف می‌کنید نسبت به حذف این کلمات اقدام کنید. البته توجه داشته باشید که برخی کلمات می‌‍توانند بصورت رایج کلمه‌ی توقف شناخته شوند اما در مسئله‌ی خاص شما اتفاقاً با اهمیت باشند.</li>\n",
    "<li><b>حذف اعداد و حروف اضافه: </b>اعداد و حروف اضافه نیز همچون کلمات توقف ممکن است با توجه به مسئله بی‌اهمیت باشند و بتوان آن‌ها را به‌کلی حذف کرد. البته ایده‌ی دیگری وجود دارد که به‌جای هر عدد یک توکن خاص مثلاً <code>NUMBER</code> قرار دهید.</li>\n",
    "<li><b>نرمال‌سازی (normalization):</b> انجام برخی اصلاحات رایج در متن جهت نرمال کردن کلمات نیز تکنیک دیگری است که کاربرد زیادی دارد. به عنوان مثال در زبان فارسی رعایت نیم‌فاصله می‌تواند یک نرمال‌سازی بسیار مفید شناخته شود. اگر این کار صورت نگیرد به عنوان مثال کلمه‌ی «نیم فاصله» با کلمه‌ی «نیم‌فاصله» کاملاً متفاوت در نظر گرفته می‌شود. اولی خود شامل دو کلمه‌ی مجزاست در حالیکه دومی یک کلمه‌ی واحد است.</li>\n",
    "<li><b>ریشه‌یابی (stemming)</b> تکنیک دیگر تبدیل کلمات به ریشه‌ی آن‌هاست. به عنوان مثال در زبان فارسی «کتاب‌ها» را می‌توان با ریشه‌ی خود یعنی «کتاب» جایگزین کنیم. با این جایگزینی مفهوم کلمه عوض نخواهد شد اما کار ماشین با متن بسیار راحت می‌شود زیرا در این حالت بین این دو تمایزی قائل نمی‌شود.</li>\n",
    "</ul>\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "در این قسمت از شما خواسته شده تا تابعی به نام <code>preprocessing</code> تعریف کنید که یک متن را به عنوان ورودی گرفته و سپس پیش‌پردازش‌های دلخواه شما بر روی آن انجام شود و در نهایت یک لیست از توکن‌های موجود در آن را برگرداند. منظور از توکن، هرکدام از اجزای موجود در متن است که کلمات، حروف،‌اعداد و... را  شامل می‌شود. به عنوان یک مثال اگر تابع شما جمله‌ی زیر را دریافت کند:\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "<center>\n",
    "'از همه نظر عالی و یک خرید خوب در  قیمت حدود۴۰ تومن'\n",
    "</center>\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "خروجی زیر برای آن تولید می‌شود: (توجه کنید که نیازی نیست خروجی تابع شما دقیقاً مشابه با این مثال باشد و مراحل پیش‌پردازش کاملاً به دلخواه شماست)\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "<center>\n",
    "['نظر', 'عالی', 'خرید', 'خوب', 'قیمت', 'تومن']\n",
    "</center>\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "<b>نکته:</b> برای پیش‌پردازش متون فارسی کتابخانه‌ها و ابزارهای مختلفی وجود دارد که می‌توانید به دلخواه خود از آن‌ها استفاده کنید. با این حال یکی از رایج‌ترین کتابخانه‌ها <a href=\"https://www.roshan-ai.ir/hazm/\" target=”_blank”>هضم</a> است که می‌توانید با نصب آن در محیط کار خود از ابزارهای موجود در آن بهره ببرید.\n",
    "برای دسترسی به لیست کلمات توقف فارسی می‌توانید به کمک <code>from hazm import stopwords_list</code>، لیست هضم را دریافت کنید.\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0f23e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = stopwords_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87d85a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuations = ['؟', '!', '.', ',', ';', ':', '،', '؛', '(', ')', '[', ']', '{', '}', '«', '»']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34703151",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"از همه نظر عالی و یک خرید خوب، در  قیمت حدود۴۰ تومن\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "318eedd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['خرید', 'قیمت', '۴۰', 'تومن']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizer = Normalizer()\n",
    "tokenizer = WordTokenizer()\n",
    "def preprocessing(text):\n",
    "    \n",
    "    # Normalize the text\n",
    "    text_normalized = normalizer.normalize(text)\n",
    "    tokens = tokenizer.tokenize(text_normalized)\n",
    "    # tokens = [token for token in tokens if token not in punctuations and token not in stopwords and not token.isdigit()]\n",
    "    tokens = [token for token in tokens if token not in punctuations and token not in stopwords]\n",
    "    return tokens\n",
    "\n",
    "preprocessing(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40eb5df5",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "مدل‌سازی\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "در این قسمت گام به گام به انجام محاسبات لازم جهت اجرای الگوریتم بیز ساده‌لوحانه (Naive Bayes) خواهیم پرداخت. در ابتدا نیاز است تا احتمال هر کلاس (<code>price_value</code> برابر <code>0</code> یا <code>1</code>) را محاسبه کنید. برای این کار تعداد داده‌های متعلق به آن کلاس را بر تعداد کل داده‌ها تقسیم کنید. حاصل را بصورت دیکشنری با فرمت <code dir=ltr>{0: P0, 1: P1}</code> در متغیر <code>prior_probability</code> ذخیره کنید. به جای <code>P0</code> احتمال برچسب <code>0</code> و به جای <code>P1</code> احتمال برچسب <code>1</code> را قرار دهید. <code>\n",
    "</font>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c0bc602",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = train_data.price_value.count()\n",
    "p0 = train_data.price_value[train_data.price_value == 0].count() / count\n",
    "p1 = train_data.price_value[train_data.price_value == 1].count() / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97a1ff35",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_probability = {0: p0, 1: p1} # To-Do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "472170a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.5205, 1: 0.4795}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prior_probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e77f58c",
   "metadata": {},
   "source": [
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "حال باید احتمال وقوع هر توکن در هر کلاس را به دست آوریم. برای این کار ویژگی ورودی مدل را تعداد رخداد یک توکن در نظر می‌گیریم. پس در ابتدا تابع <code>token_counter</code> را به گونه‌ای تکمیل کنید که مجموعه‌ای (آرایه‌ای) از متن‌ها را به عنوان ورودی گرفته و یک دیکشنری از تعداد رخداد هر کلمه در میان تمام آن‌ها تولید کند. یعنی به ازای هر متن موجود در ورودی، ابتدا آن را به تابع <code>preprocessing</code> بدهید تا پیش‌پردازش‌های مختلف را روی متن اعمال کند و توکن‌های موجود در آن را برگرداند. سپس به ازای هر توکن یک واحد به تعداد رخداد آن در دیکشنری اضافه کنید. فرمت دیکشنری شما باید به گونه‌ای باشد که نمایه‌ی آن، یک کلمه و مقدار آن، تعداد رخداد آن کلمه در میان تمام متون ورودی تابع باشد.\n",
    "</font>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe99c5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c22875e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def token_counter(texts):\n",
    "    \n",
    "#     count_dict = {}\n",
    "#     for text in texts:\n",
    "#         preprocessed = preprocessing(text)\n",
    "#         for token in preprocessed:\n",
    "#             if token in count_dict:\n",
    "#                 count_dict[token] += 1\n",
    "#             else:\n",
    "#                 count_dict[token] = 1\n",
    "#     # To-Do\n",
    "#     return count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0db88986",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def token_counter(texts):\n",
    "    count_dict = defaultdict(int)\n",
    "    for text in texts:\n",
    "        preprocessed = preprocessing(text)\n",
    "        for token in preprocessed:\n",
    "            count_dict[token] += 1\n",
    "    return dict(count_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508b8de4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0db5a747",
   "metadata": {},
   "source": [
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "اکنون می‌توانید متون هرکدام از کلاس‌ها را به تابع <code>token_counter</code> بدهید تا تعداد رخداد هر کلمه در آن کلاس شمرده شود. یکبار کامنت‌هایی که برچسب <code>0</code> دارند را جدا کرده و به این تابع بدهید و خروجی را در متغیر <code>negative_class_count</code> ذخیره کنید. بار دیگر همین کار را برای برچسب <code>1</code> تکرار کرده و نتیجه را در متغیر <code>positive_class_count</code> ذخیره کنید.\n",
    "</font>\n",
    "</p>\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "<span style=\"color: green\"><b>نکته: </b></span> در این تمرین اگر برخی سلول‌ها تا یک یا چند دقیقه طول کشیدند تعجب نکنید و به علت حجم بالای داده و محاسبات طبیعی است.\n",
    "</font>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c7363d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 32000 entries, 14307 to 15795\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   comment      32000 non-null  object\n",
      " 1   price_value  32000 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 750.0+ KB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c86a5e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm\n",
    "\n",
    "def token_counter_threaded(texts):\n",
    "    count_dict = {}\n",
    "    \n",
    "    # Define a helper function to process each text\n",
    "    def process_text(text):\n",
    "        return preprocessing(text)\n",
    "    \n",
    "    # Use ThreadPoolExecutor to process texts in parallel\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        results = list(tqdm(executor.map(process_text, texts), total=len(texts), desc=\"Processing texts\"))\n",
    "    \n",
    "    for tokens in results:\n",
    "        for token in tokens:\n",
    "            if token in count_dict:\n",
    "                count_dict[token] += 1\n",
    "            else:\n",
    "                count_dict[token] = 1\n",
    "    return count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b389b5ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing texts: 100%|██████████| 16656/16656 [00:00<00:00, 369435.89it/s]\n"
     ]
    }
   ],
   "source": [
    "negative_class_count = token_counter_threaded(train_data[train_data.price_value == 0].comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e6d2464",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_class_count = token_counter(train_data[train_data.price_value == 1].comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e97501",
   "metadata": {},
   "source": [
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "وقت آن رسیده که به طراحی بخش اصلی الگوریتم یعنی محاسبه‌ی احتمال یک کلاس به شرط یک متن بپردازیم تا آن کلاسی که بیشترین احتمال را کسب کرده به عنوان پیش‌بینی خروجی داده شود. جهت محاسبه‌ی احتمال یک کلاس به شرط مشاهده‌ی یک متن (لیستی از توکن‌ها) طبق ایده‌ی الگوریتم بیز ساده‌لوحانه کافیست احتمال رخداد هرکدام از اجزای آن (در اینجا توکن‌ها) را به شرط آن کلاس محاسبه کرده و در همدیگر ضرب کنیم. حاصل را نیز در نهایت در احتمال آن کلاس ضرب خواهیم کرد. یعنی خواهیم داشت:\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bc1b77",
   "metadata": {},
   "source": [
    "$P(class|t_1, t_2, ..., t_n)=P(t_1, t_2, ..., t_n|class)\\times P(class)=P(t_1|class)\\times P(t_2|class)\\times ...\\times P(t_n|class)\\times P(class)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971e890d",
   "metadata": {},
   "source": [
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "و اما برای محاسبه‌ی احتمال رخداد هر توکن به شرط یک کلاس می‌توانیم تعداد رخداد توکن در میان متن‌های آن کلاس را بر مجموع رخداد توکن‌های متون مربوط به آن کلاس تقسیم کنیم. تعداد رخداد هر توکن در هر کلاس در دیکشنری‌های <code>positive_class_count</code> و <code>negative_class_count</code> ذخیره شده است. مجموع رخداد توکن‌های یک کلاس را نیز می‌توانید با جمع تمام مقادیر موجود در دیکشنری آن کلاس به‌دست آورید. اگر بخواهیم مفهوم این قسمت را به شکل فرمول نمایش دهیم خواهیم داشت:\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01851508",
   "metadata": {},
   "source": [
    "$\\large P(w_i|class)=\\frac{count(t_i, class)}{\\sum_{t \\in V}{count(t, class)}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51f4c23",
   "metadata": {},
   "source": [
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "با این حال فرمول بالا چندان عملکرد خوبی نخواهد داشت. فرض کنید یک متن آزمون دارید و می‌خواهید احتمال هر توکن آن در یک کلاس را محاسبه کنید اما آن توکن تاکنون دیده نشده و تعداد رخدادش صفر است. در اینصورت احتمال توکن به شرط کلاس معادل صفر شده و هنگامیکه این عدد در احتمال سایر توکن‌ها ضرب می‌شود حاصل را به کلی صفر می‌کند. جهت رفع این مشکل ایده‌ای با نام <i>add-1 smoothing</i> مطرح می‌شود که می‌گوید تعداد رخداد کلمه‌ای که تاکنون دیده‌نشده به‌جای صفر معادل یک در نظر گرفته شود. جهت اعمال این تغییر لازم است به تعداد تکرار تمام توکن‌ها نیز یک واحد اضافه کنیم و جهت آنکه نسبت‌ها به هم نخورد نیاز است تا در مخرج کسر نیز اندازه‌ی لغت‌نامه را قرار دهیم. منظور از لغت‌نامه که آن را در فرمول با <code>V</code> نشان می‌دهیم تمام توکن‌های یکتای موجود است. یعنی باید توکن‌های موجود در دیکشنری تمام کلاس‌ها را با هم ترکیب کنید و موارد یکتا را به دست آورید. با اعمال تغییراتی که شرح داده شد نهایتاً به فرمول زیر خواهیم رسید:\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5190c063",
   "metadata": {},
   "source": [
    "$\\large P(w_i|class)=\\frac{count(t_i, class) + 1}{(\\sum_{t \\in V}{count(t, class)}) + |V|}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d412be",
   "metadata": {},
   "source": [
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "حال از شما می‌خواهیم که در تابع <code>compute_probability</code> یک متن و یک کلاس (<code>0</code> یا <code>1</code>) را گرفته و طبق فرمول‌های معرفی‌شده به محاسبه‌ی احتمال آن کلاس به شرط آن متن بپردازد. یعنی نیاز است احتمال هر توکن به شرط آن کلاس را محاسبه کرده، حاصل تمام آن‌ها را در هم ضرب کرده، نهایتاً در احتمال آن کلاس ضرب کنید و حاصل را برگردانید.\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "790b535a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_probability(text, cls):\n",
    "    probability = prior_probability[cls]\n",
    "    if cls == 1:\n",
    "        for token in text:\n",
    "            probability *= (positive_class_count.get(token, 0) + 1) / (sum(positive_class_count.values()) + len(positive_class_count))\n",
    "    else:\n",
    "        for token in text:\n",
    "            probability *= (negative_class_count.get(token, 0) + 1) / (sum(negative_class_count.values()) + len(negative_class_count))\n",
    "    return probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0486b9b",
   "metadata": {},
   "source": [
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "اکنون تابع <code>predict</code> را به گونه‌ای تکمیل کنید که لیستی از متن‌ها را گرفته و یک آرایه‌ی نامپای تک‌بعدی از برچسب پیش‌بینی‌شده برای آن‌ها تولید کند. جهت پیش‌بینی برچسب یک متن کافیست متن ورودی را یک‌بار با کلاس <code>0</code> و یک‌بار با کلاس <code>1</code> به تابع <code>compute_proability</code> بدهید تا احتمال هر کلاس محاسبه شود. سپس آن کلاسی که مقدار احتمال بیشتری را تولید کرده است به عنوان برچسب پیش‌بینی‌شده انتخاب کنید.\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96687ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test):\n",
    "    predictions = []\n",
    "    for text in test:\n",
    "        preprocessed = preprocessing(text)\n",
    "        probability_0 = compute_probability(preprocessed, 0)\n",
    "        probability_1 = compute_probability(preprocessed, 1)\n",
    "        # print(probability_0, probability_1)\n",
    "        predictions.append(0 if probability_0 > probability_1 else 1)\n",
    "    return np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90026850",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ['قیمتش خوب بود به مولا', 'قیمتش خوب نبود']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e8c93cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 32000 entries, 14307 to 15795\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   comment      32000 non-null  object\n",
      " 1   price_value  32000 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 750.0+ KB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33da5d2a",
   "metadata": {},
   "source": [
    "<h3 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "ارزیابی\n",
    "</font>\n",
    "</h3>\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "ساخت مدل بیز ساده‌لوحانه به اتمام رسید و اکنون می‌توانید متن‌های خود را به مدل بدهید تا برچسب آن‌ها را پیش‌بینی کند. در این مرحله می‌توانید ابتدا داده‌های آموزشی را به تابع <code>predict</code> بدهید و پیش‌بینی‌های تولیدی را با برچسب‌های واقعی مقایسه کنید تا دقت مدل خود را بر روی داده‌های آموزشی بسنجید. این دقت می‌تواند تا حدی در اطمینان شما به پیاده‌سازیِ انجام‌گرفته کمک کند. جهت محاسبه‌ی دقت می‌توانید از تابع آماده‌ی <code>accuracy_score</code> استفاده کنید و در سیستم داوری نیز خروجی شما با این معیار سنجیده خواهد شد.\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c4403994",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_target = train_data['price_value']\n",
    "train_data = train_data.drop(columns=['price_value'])\n",
    "\n",
    "valid_data_target = valid_data['price_value']\n",
    "valid_data = valid_data.drop(columns=['price_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2fb4965f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 32000 entries, 14307 to 15795\n",
      "Data columns (total 1 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   comment  32000 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 500.0+ KB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cee1b883",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting on train data: 100%|██████████| 32000/32000 [02:51<00:00, 186.50it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.898125"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_predictions = predict(tqdm(train_data['comment'].tolist(), desc=\"Predicting on train data\"))\n",
    "accuracy_score(train_data_target, train_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "930ff7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32000 entries, 0 to 31999\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   0       32000 non-null  int32\n",
      "dtypes: int32(1)\n",
      "memory usage: 125.1 KB\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(train_predictions).info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "02d6d22c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting on validation data:   0%|          | 0/8000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting on validation data: 100%|██████████| 8000/8000 [00:42<00:00, 188.04it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.823625"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_predictions = predict(tqdm(valid_data['comment'].tolist(), desc=\"Predicting on validation data\"))\n",
    "accuracy_score(valid_data_target, valid_predictions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ddad09cf",
   "metadata": {},
   "source": [
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font color=\"red\"><b color='red'>توجه:</b></font>\n",
    "<font face=\"vazir\" size=3>\n",
    " جهت کسب امتیاز کامل نیاز است تا پاسخ شما حداقل امتیاز <code>80</code> را با توجه به معیار معرفی‌شده کسب نماید.\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4e9984de",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    " پیش‌بینی برای داده تست و خروجی\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    اکنون نیاز است متون مربوط به مجموعه‌ی آزمون را به تابع <code>predict</code> بدهید تا مدل شما به پیش‌بینی برچسب برای آن‌ها بپردازد. در نهایت نتایج به‌دست‌آمده را در قالب جدول زیر آماده کنید و در دیتافریم <code>submission</code> ذخیره کنید.\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "<center>\n",
    "<div dir=rtl style=\"direction: rtl;line-height:200%;font-family:vazir;font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    \n",
    "|ستون|توضیحات|\n",
    "|:------:|:---:|\n",
    "|<code>price_value</code>|برچسب پیش‌بینی‌شده|\n",
    "    \n",
    "</font>\n",
    "</div>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3d4a0844",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting on validation data: 100%|██████████| 8000/8000 [00:42<00:00, 186.07it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 0, 1])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = predict(tqdm(test_data['comment'].tolist(), desc=\"Predicting on validation data\")) # To-Do\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "739e6e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'price_value': submission})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6d990b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8000 entries, 0 to 7999\n",
      "Data columns (total 1 columns):\n",
      " #   Column       Non-Null Count  Dtype\n",
      "---  ------       --------------  -----\n",
      " 0   price_value  8000 non-null   int32\n",
      "dtypes: int32(1)\n",
      "memory usage: 31.4 KB\n"
     ]
    }
   ],
   "source": [
    "submission.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a77e7cd",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "<b>سلول جواب‌ساز</b>\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    برای ساخته‌شدن فایل <code>result.zip</code> سلول زیر را اجرا کنید. توجه داشته باشید که پیش از اجرای سلول زیر تغییرات اعمال شده در نت‌بوک را ذخیره کرده باشید (<code>ctrl+s</code>) تا در صورت نیاز به پشتیبانی امکان بررسی کد شما وجود داشته باشد.\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2c3bcd76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Paths:\n",
      "['comment_mining.ipynb', 'submission.csv']\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import joblib\n",
    "\n",
    "def compress(file_names):\n",
    "    print(\"File Paths:\")\n",
    "    print(file_names)\n",
    "    compression = zipfile.ZIP_DEFLATED\n",
    "    with zipfile.ZipFile(\"result.zip\", mode=\"w\") as zf:\n",
    "        for file_name in file_names:\n",
    "            zf.write('./' + file_name, file_name, compress_type=compression)\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "file_names = ['comment_mining.ipynb', 'submission.csv']\n",
    "compress(file_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
